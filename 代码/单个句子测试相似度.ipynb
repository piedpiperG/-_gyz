{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 文本相似度检测"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1130402483ff6ac7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "被检测的文本数据集，分为了三类"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77eb0f0630b7658a"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# 定义文本对\n",
    "texts = [\n",
    "    # 完全相同的文本对\n",
    "    ('今年夏天格外炎热，许多城市的温度都达到了历史新高，专家建议民众减少午后外出，多补充水分，尽量待在空调房内避暑。',\n",
    "     '今年夏天格外炎热，许多城市的温度都达到了历史新高，专家建议民众减少午后外出，多补充水分，尽量待在空调房内避暑。'),\n",
    "    # 轻微修改的文本对\n",
    "    ('随着科技的迅速发展，人工智能在医疗、教育、交通等多个领域的应用越来越广泛，它正逐渐改变着人们的生活方式和工作模式。',\n",
    "     '人工智能的快速发展推动了其在医疗、教育、交通等众多领域的广泛应用，这正在慢慢地改变人们的日常生活和工作方式。'),\n",
    "    # 概念上相似但表达方式不同的文本对\n",
    "    ('今年入冬以来，北方多地出现了严重的雾霾天气，能见度低，对人们的健康和日常出行造成了极大影响。',\n",
    "     '自从这个冬季开始，北方地区频繁遭受雾霾侵袭，低能见度严重威胁到居民健康及其日常生活。'),\n",
    "    ('太阳从东边升起', '太阳从西边升起')\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T07:06:33.881954900Z",
     "start_time": "2024-03-28T07:06:33.867159600Z"
    }
   },
   "id": "807f70286e1136bd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 余弦相似度cosine_similarity"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e58c9aef51379ff"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Edgar\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.742 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['充水', '天格', '今年夏天', '避暑', '专家建议', '炎热', '外出', '空调', '水分', '午后', '民众', '夏天', '温度', '新高', '补充', '专家', '建议', '减少', '城市', '历史']\n",
      "['充水', '天格', '今年夏天', '避暑', '专家建议', '炎热', '外出', '空调', '水分', '午后', '民众', '夏天', '温度', '新高', '补充', '专家', '建议', '减少', '城市', '历史']\n",
      "文本1: \"今年夏天格外炎热，许多城市的温度都达到了历史新高，专家建议民众减少午后外出，多补充水分，尽量待在空调房内避暑。\"\n",
      "文本2: \"今年夏天格外炎热，许多城市的温度都达到了历史新高，专家建议民众减少午后外出，多补充水分，尽量待在空调房内避暑。\"\n",
      "相似度: 1.0000000000000002\n",
      "\n",
      "['人工智能', '智能', '人工', '医疗', '多个', '模式', '交通', '科技', '教育', '越来越', '领域', '改变', '方式', '生活', '工作', '发展']\n",
      "['人工智能', '日常生活', '广泛应用', '智能', '日常', '人工', '医疗', '慢慢', '交通', '众多', '快速', '教育', '领域', '推动', '改变', '方式', '生活', '工作', '发展']\n",
      "文本1: \"随着科技的迅速发展，人工智能在医疗、教育、交通等多个领域的应用越来越广泛，它正逐渐改变着人们的生活方式和工作模式。\"\n",
      "文本2: \"人工智能的快速发展推动了其在医疗、教育、交通等众多领域的广泛应用，这正在慢慢地改变人们的日常生活和工作方式。\"\n",
      "相似度: 0.6882472016116852\n",
      "\n",
      "['入冬', '能见度', '出行', '日常', '天气', '北方', '健康', '影响']\n",
      "['低能', '北方地区', '严重威胁', '能见度', '侵袭', '日常生活', '日常', '遭受', '频繁', '冬季', '威胁', '北方', '健康', '居民', '生活', '地区']\n",
      "文本1: \"今年入冬以来，北方多地出现了严重的雾霾天气，能见度低，对人们的健康和日常出行造成了极大影响。\"\n",
      "文本2: \"自从这个冬季开始，北方地区频繁遭受雾霾侵袭，低能见度严重威胁到居民健康及其日常生活。\"\n",
      "相似度: 0.35355339059327373\n",
      "\n",
      "['升起', '东边', '太阳']\n",
      "['升起', '西边', '太阳']\n",
      "文本1: \"太阳从东边升起\"\n",
      "文本2: \"太阳从西边升起\"\n",
      "相似度: 0.6666666666666669\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# 正则包\n",
    "import re\n",
    "# html 包\n",
    "import html\n",
    "# 自然语言处理包\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "# 机器学习包\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "class CosineSimilarity(object):\n",
    "    \"\"\"\n",
    "    余弦相似度\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, content_x1, content_y2):\n",
    "        self.s1 = content_x1\n",
    "        self.s2 = content_y2\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_keyword(content):  # 提取关键词\n",
    "        # 切割\n",
    "        seg = [i for i in jieba.cut(content, cut_all=True) if i != '']\n",
    "        # 提取关键词\n",
    "        keywords = jieba.analyse.extract_tags(\"|\".join(seg), topK=200, withWeight=False)\n",
    "        print(keywords)\n",
    "        return keywords\n",
    "\n",
    "    @staticmethod\n",
    "    def one_hot(word_dict, keywords):  # oneHot编码\n",
    "        # cut_code = [word_dict[word] for word in keywords]\n",
    "        cut_code = [0] * len(word_dict)\n",
    "        for word in keywords:\n",
    "            cut_code[word_dict[word]] += 1\n",
    "        return cut_code\n",
    "\n",
    "    def main(self):\n",
    "        # 去除停用词\n",
    "        jieba.analyse.set_stop_words('data/stopwords.txt')\n",
    "\n",
    "        # 提取关键词\n",
    "        keywords1 = self.extract_keyword(self.s1)\n",
    "        keywords2 = self.extract_keyword(self.s2)\n",
    "        # 词的并集\n",
    "        union = set(keywords1).union(set(keywords2))\n",
    "        # 编码\n",
    "        word_dict = {}\n",
    "        i = 0\n",
    "        for word in union:\n",
    "            word_dict[word] = i\n",
    "            i += 1\n",
    "        # oneHot编码\n",
    "        s1_cut_code = self.one_hot(word_dict, keywords1)\n",
    "        s2_cut_code = self.one_hot(word_dict, keywords2)\n",
    "        # 余弦相似度计算\n",
    "        sample = [s1_cut_code, s2_cut_code]\n",
    "        # 除零处理\n",
    "        try:\n",
    "            sim = cosine_similarity(sample)\n",
    "            return sim[1][0]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return 0.0\n",
    "\n",
    "\n",
    "# 计算并打印相似度\n",
    "for text_pair in texts:\n",
    "    cs = CosineSimilarity(*text_pair)\n",
    "    similarity = cs.main()\n",
    "    print(f\"文本1: \\\"{text_pair[0]}\\\"\")\n",
    "    print(f\"文本2: \\\"{text_pair[1]}\\\"\")\n",
    "    print(f\"相似度: {similarity}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T07:07:15.319975200Z",
     "start_time": "2024-03-28T07:07:12.835915300Z"
    }
   },
   "id": "38453a1c4c8fd28c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### jaccard相似度"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2c272059a941400"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['充水', '天格', '今年夏天', '避暑', '专家建议', '炎热', '外出', '空调', '水分', '午后', '民众', '夏天', '温度', '新高', '补充', '专家', '建议', '减少', '城市', '历史']\n",
      "['充水', '天格', '今年夏天', '避暑', '专家建议', '炎热', '外出', '空调', '水分', '午后', '民众', '夏天', '温度', '新高', '补充', '专家', '建议', '减少', '城市', '历史']\n",
      "文本1: \"今年夏天格外炎热，许多城市的温度都达到了历史新高，专家建议民众减少午后外出，多补充水分，尽量待在空调房内避暑。\"\n",
      "文本2: \"今年夏天格外炎热，许多城市的温度都达到了历史新高，专家建议民众减少午后外出，多补充水分，尽量待在空调房内避暑。\"\n",
      "Jaccard相似度: 1.0\n",
      "\n",
      "['人工智能', '智能', '人工', '医疗', '多个', '模式', '交通', '科技', '教育', '越来越', '领域', '改变', '方式', '生活', '工作', '发展']\n",
      "['人工智能', '日常生活', '广泛应用', '智能', '日常', '人工', '医疗', '慢慢', '交通', '众多', '快速', '教育', '领域', '推动', '改变', '方式', '生活', '工作', '发展']\n",
      "文本1: \"随着科技的迅速发展，人工智能在医疗、教育、交通等多个领域的应用越来越广泛，它正逐渐改变着人们的生活方式和工作模式。\"\n",
      "文本2: \"人工智能的快速发展推动了其在医疗、教育、交通等众多领域的广泛应用，这正在慢慢地改变人们的日常生活和工作方式。\"\n",
      "Jaccard相似度: 0.5217391304347826\n",
      "\n",
      "['入冬', '能见度', '出行', '日常', '天气', '北方', '健康', '影响']\n",
      "['低能', '北方地区', '严重威胁', '能见度', '侵袭', '日常生活', '日常', '遭受', '频繁', '冬季', '威胁', '北方', '健康', '居民', '生活', '地区']\n",
      "文本1: \"今年入冬以来，北方多地出现了严重的雾霾天气，能见度低，对人们的健康和日常出行造成了极大影响。\"\n",
      "文本2: \"自从这个冬季开始，北方地区频繁遭受雾霾侵袭，低能见度严重威胁到居民健康及其日常生活。\"\n",
      "Jaccard相似度: 0.2\n",
      "\n",
      "['升起', '东边', '太阳']\n",
      "['升起', '西边', '太阳']\n",
      "文本1: \"太阳从东边升起\"\n",
      "文本2: \"太阳从西边升起\"\n",
      "Jaccard相似度: 0.5\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# 正则包\n",
    "import re\n",
    "# 自然语言处理包\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "# html 包\n",
    "import html\n",
    "\n",
    "\n",
    "class JaccardSimilarity(object):\n",
    "    \"\"\"\n",
    "    jaccard相似度\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, content_x1, content_y2):\n",
    "        self.s1 = content_x1\n",
    "        self.s2 = content_y2\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_keyword(content):  # 提取关键词\n",
    "        # 切割\n",
    "        seg = [i for i in jieba.cut(content, cut_all=True) if i != '']\n",
    "        # 提取关键词\n",
    "        keywords = jieba.analyse.extract_tags(\"|\".join(seg), topK=200, withWeight=False)\n",
    "        print(keywords)\n",
    "        return keywords\n",
    "\n",
    "    def main(self):\n",
    "        # 去除停用词\n",
    "        jieba.analyse.set_stop_words('data/stopwords.txt')\n",
    "\n",
    "        # 分词与关键词提取\n",
    "        keywords_x = self.extract_keyword(self.s1)\n",
    "        keywords_y = self.extract_keyword(self.s2)\n",
    "\n",
    "        # jaccard相似度计算\n",
    "        intersection = len(list(set(keywords_x).intersection(set(keywords_y))))\n",
    "        union = len(list(set(keywords_x).union(set(keywords_y))))\n",
    "        # 除零处理\n",
    "        sim = float(intersection) / union if union != 0 else 0\n",
    "        return sim\n",
    "\n",
    "\n",
    "# 计算并打印相似度\n",
    "for text_pair in texts:\n",
    "    js = JaccardSimilarity(*text_pair)\n",
    "    similarity = js.main()\n",
    "    print(f\"文本1: \\\"{text_pair[0]}\\\"\")\n",
    "    print(f\"文本2: \\\"{text_pair[1]}\\\"\")\n",
    "    print(f\"Jaccard相似度: {similarity}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T07:07:22.976660500Z",
     "start_time": "2024-03-28T07:07:22.937868300Z"
    }
   },
   "id": "9db0e2e4b41400a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 编辑距离Levenshtein"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1b0c3fa717b8756"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本1: \"今年夏天格外炎热，许多城市的温度都达到了历史新高，专家建议民众减少午后外出，多补充水分，尽量待在空调房内避暑。\"\n",
      "文本2: \"今年夏天格外炎热，许多城市的温度都达到了历史新高，专家建议民众减少午后外出，多补充水分，尽量待在空调房内避暑。\"\n",
      "Levenshtein相似度: 1.0\n",
      "\n",
      "文本1: \"随着科技的迅速发展，人工智能在医疗、教育、交通等多个领域的应用越来越广泛，它正逐渐改变着人们的生活方式和工作模式。\"\n",
      "文本2: \"人工智能的快速发展推动了其在医疗、教育、交通等众多领域的广泛应用，这正在慢慢地改变人们的日常生活和工作方式。\"\n",
      "Levenshtein相似度: 0.7172413793103448\n",
      "\n",
      "文本1: \"今年入冬以来，北方多地出现了严重的雾霾天气，能见度低，对人们的健康和日常出行造成了极大影响。\"\n",
      "文本2: \"自从这个冬季开始，北方地区频繁遭受雾霾侵袭，低能见度严重威胁到居民健康及其日常生活。\"\n",
      "Levenshtein相似度: 0.45999999999999996\n",
      "\n",
      "文本1: \"太阳从东边升起\"\n",
      "文本2: \"太阳从西边升起\"\n",
      "Levenshtein相似度: 0.9\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# 正则包\n",
    "import re\n",
    "# html 包\n",
    "import html\n",
    "# 自然语言处理包\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "# 编辑距离包\n",
    "import Levenshtein\n",
    "\n",
    "\n",
    "class LevenshteinSimilarity(object):\n",
    "    \"\"\"\n",
    "    编辑距离\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, content_x1, content_y2):\n",
    "        self.s1 = content_x1\n",
    "        self.s2 = content_y2\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_keyword(content):  # 提取关键词\n",
    "        # 切割\n",
    "        seg = [i for i in jieba.cut(content, cut_all=True) if i != '']\n",
    "        # 提取关键词\n",
    "        keywords = jieba.analyse.extract_tags(\"|\".join(seg), topK=200, withWeight=False)\n",
    "        return keywords\n",
    "\n",
    "    def main(self):\n",
    "        # 去除停用词\n",
    "        jieba.analyse.set_stop_words('data/stopwords.txt')\n",
    "\n",
    "        # 提取关键词\n",
    "        keywords1 = ', '.join(self.extract_keyword(self.s1))\n",
    "        keywords2 = ', '.join(self.extract_keyword(self.s2))\n",
    "\n",
    "        # ratio计算2个字符串的相似度，它是基于最小编辑距离\n",
    "        distances = Levenshtein.ratio(keywords1, keywords2)\n",
    "        return distances\n",
    "\n",
    "\n",
    "# 计算并打印相似度\n",
    "for text_pair in texts:\n",
    "    ls = LevenshteinSimilarity(*text_pair)\n",
    "    similarity = ls.main()\n",
    "    print(f\"文本1: \\\"{text_pair[0]}\\\"\")\n",
    "    print(f\"文本2: \\\"{text_pair[1]}\\\"\")\n",
    "    print(f\"Levenshtein相似度: {similarity}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T07:07:38.841475200Z",
     "start_time": "2024-03-28T07:07:37.749811700Z"
    }
   },
   "id": "a8bfbf422afe6eac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MinHash"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b460182359a8542"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本1: \"今年夏天格外炎热，许多城市的温度都达到了历史新高，专家建议民众减少午后外出，多补充水分，尽量待在空调房内避暑。\"\n",
      "文本2: \"今年夏天格外炎热，许多城市的温度都达到了历史新高，专家建议民众减少午后外出，多补充水分，尽量待在空调房内避暑。\"\n",
      "MinHash相似度: 1.0\n",
      "\n",
      "文本1: \"随着科技的迅速发展，人工智能在医疗、教育、交通等多个领域的应用越来越广泛，它正逐渐改变着人们的生活方式和工作模式。\"\n",
      "文本2: \"人工智能的快速发展推动了其在医疗、教育、交通等众多领域的广泛应用，这正在慢慢地改变人们的日常生活和工作方式。\"\n",
      "MinHash相似度: 0.578125\n",
      "\n",
      "文本1: \"今年入冬以来，北方多地出现了严重的雾霾天气，能见度低，对人们的健康和日常出行造成了极大影响。\"\n",
      "文本2: \"自从这个冬季开始，北方地区频繁遭受雾霾侵袭，低能见度严重威胁到居民健康及其日常生活。\"\n",
      "MinHash相似度: 0.2265625\n",
      "\n",
      "文本1: \"太阳从东边升起\"\n",
      "文本2: \"太阳从西边升起\"\n",
      "MinHash相似度: 0.53125\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# 正则包\n",
    "import re\n",
    "# 自然语言处理包\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "# html 包\n",
    "import html\n",
    "# 数据集处理包\n",
    "from datasketch import MinHash\n",
    "\n",
    "\n",
    "class MinHashSimilarity(object):\n",
    "    \"\"\"\n",
    "    MinHash\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, content_x1, content_y2):\n",
    "        self.s1 = content_x1\n",
    "        self.s2 = content_y2\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_keyword(content):  # 提取关键词\n",
    "        # 切割\n",
    "        seg = [i for i in jieba.cut(content, cut_all=True) if i != '']\n",
    "        # 提取关键词\n",
    "        keywords = jieba.analyse.extract_tags(\"|\".join(seg), topK=200, withWeight=False)\n",
    "        return keywords\n",
    "\n",
    "    def main(self):\n",
    "        # 去除停用词\n",
    "        jieba.analyse.set_stop_words('data/stopwords.txt')\n",
    "\n",
    "        # MinHash计算\n",
    "        m1, m2 = MinHash(), MinHash()\n",
    "        # 提取关键词\n",
    "        s1 = self.extract_keyword(self.s1)\n",
    "        s2 = self.extract_keyword(self.s2)\n",
    "\n",
    "        for data in s1:\n",
    "            m1.update(data.encode('utf8'))\n",
    "        for data in s2:\n",
    "            m2.update(data.encode('utf8'))\n",
    "\n",
    "        return m1.jaccard(m2)\n",
    "\n",
    "\n",
    "# 计算并打印相似度\n",
    "for text_pair in texts:\n",
    "    mhs = MinHashSimilarity(*text_pair)\n",
    "    similarity = mhs.main()\n",
    "    print(f\"文本1: \\\"{text_pair[0]}\\\"\")\n",
    "    print(f\"文本2: \\\"{text_pair[1]}\\\"\")\n",
    "    print(f\"MinHash相似度: {similarity}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T07:07:45.136547800Z",
     "start_time": "2024-03-28T07:07:45.030549200Z"
    }
   },
   "id": "43f87905badbd36"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SimHash + 海明距离"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a9c14f749fc15f9"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本1: \"今年夏天格外炎热，许多城市的温度都达到了历史新高，专家建议民众减少午后外出，多补充水分，尽量待在空调房内避暑。\"\n",
      "文本2: \"今年夏天格外炎热，许多城市的温度都达到了历史新高，专家建议民众减少午后外出，多补充水分，尽量待在空调房内避暑。\"\n",
      "汉明距离: 0\n",
      "相似度: 1.0\n",
      "\n",
      "文本1: \"随着科技的迅速发展，人工智能在医疗、教育、交通等多个领域的应用越来越广泛，它正逐渐改变着人们的生活方式和工作模式。\"\n",
      "文本2: \"人工智能的快速发展推动了其在医疗、教育、交通等众多领域的广泛应用，这正在慢慢地改变人们的日常生活和工作方式。\"\n",
      "汉明距离: 24\n",
      "相似度: 0.625\n",
      "\n",
      "文本1: \"今年入冬以来，北方多地出现了严重的雾霾天气，能见度低，对人们的健康和日常出行造成了极大影响。\"\n",
      "文本2: \"自从这个冬季开始，北方地区频繁遭受雾霾侵袭，低能见度严重威胁到居民健康及其日常生活。\"\n",
      "汉明距离: 20\n",
      "相似度: 0.6875\n",
      "\n",
      "文本1: \"太阳从东边升起\"\n",
      "文本2: \"太阳从西边升起\"\n",
      "汉明距离: 21\n",
      "相似度: 0.671875\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# 正则\n",
    "import re\n",
    "# html 包\n",
    "import html\n",
    "# 数学包\n",
    "import math\n",
    "# 自然语言处理包\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "\n",
    "\n",
    "class SimHashSimilarity(object):\n",
    "    \"\"\"\n",
    "    SimHash\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, content_x1, content_y2):\n",
    "        self.s1 = content_x1\n",
    "        self.s2 = content_y2\n",
    "\n",
    "    @staticmethod\n",
    "    def get_bin_str(source):  # 字符串转二进制\n",
    "        if source == \"\":\n",
    "            return 0\n",
    "        else:\n",
    "            t = ord(source[0]) << 7\n",
    "            m = 1000003\n",
    "            mask = 2 ** 128 - 1\n",
    "            for c in source:\n",
    "                t = ((t * m) ^ ord(c)) & mask\n",
    "            t ^= len(source)\n",
    "            if t == -1:\n",
    "                t = -2\n",
    "            t = bin(t).replace('0b', '').zfill(64)[-64:]\n",
    "            return str(t)\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_keyword(content):  # 提取关键词\n",
    "        # 正则过滤 html 标签\n",
    "        re_exp = re.compile(r'(<style>.*?</style>)|(<[^>]+>)', re.S)\n",
    "        content = re_exp.sub(' ', content)\n",
    "        # html 转义符实体化\n",
    "        content = html.unescape(content)\n",
    "        # 切割\n",
    "        seg = [i for i in jieba.cut(content, cut_all=True) if i != '']\n",
    "        # 提取关键词\n",
    "        keywords = jieba.analyse.extract_tags(\"|\".join(seg), topK=200, withWeight=True)\n",
    "        return keywords\n",
    "\n",
    "    def run(self, keywords):\n",
    "        ret = []\n",
    "        for keyword, weight in keywords:\n",
    "            bin_str = self.get_bin_str(keyword)\n",
    "            key_list = []\n",
    "            for c in bin_str:\n",
    "                weight = math.ceil(weight)\n",
    "                if c == \"1\":\n",
    "                    key_list.append(int(weight))\n",
    "                else:\n",
    "                    key_list.append(-int(weight))\n",
    "            ret.append(key_list)\n",
    "        # 对列表进行\"降维\"\n",
    "        rows = len(ret)\n",
    "        cols = len(ret[0])\n",
    "        result = []\n",
    "        for i in range(cols):\n",
    "            tmp = 0\n",
    "            for j in range(rows):\n",
    "                tmp += int(ret[j][i])\n",
    "            if tmp > 0:\n",
    "                tmp = \"1\"\n",
    "            elif tmp <= 0:\n",
    "                tmp = \"0\"\n",
    "            result.append(tmp)\n",
    "        return \"\".join(result)\n",
    "\n",
    "    def main(self):\n",
    "        # 去除停用词\n",
    "        jieba.analyse.set_stop_words('data/stopwords.txt')\n",
    "\n",
    "        # 提取关键词\n",
    "        s1 = self.extract_keyword(self.s1)\n",
    "        s2 = self.extract_keyword(self.s2)\n",
    "\n",
    "        sim_hash1 = self.run(s1)\n",
    "        sim_hash2 = self.run(s2)\n",
    "        # print(f'相似哈希指纹1: {sim_hash1}\\n相似哈希指纹2: {sim_hash2}')\n",
    "        length = 0\n",
    "        for index, char in enumerate(sim_hash1):\n",
    "            if char == sim_hash2[index]:\n",
    "                continue\n",
    "            else:\n",
    "                length += 1\n",
    "        return length\n",
    "\n",
    "\n",
    "# 实例化SimHashSimilarity并计算相似度\n",
    "for text_pair in texts:\n",
    "    simhash_similarity = SimHashSimilarity(*text_pair)\n",
    "    hamming_distance = simhash_similarity.main()\n",
    "    similarity = 1 - hamming_distance / 64.0  # 假设SimHash值长度为64位\n",
    "    print(f\"文本1: \\\"{text_pair[0]}\\\"\")\n",
    "    print(f\"文本2: \\\"{text_pair[1]}\\\"\")\n",
    "    print(f\"汉明距离: {hamming_distance}\")\n",
    "    print(f\"相似度: {similarity}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T07:07:49.905220700Z",
     "start_time": "2024-03-28T07:07:49.845161500Z"
    }
   },
   "id": "1821e7e474f0d40f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据集评测各个算法的性能"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12720afb0162d241"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CosineSimilarity Accuracy: 0.3203\n",
      "JaccardSimilarity Accuracy: 0.3837\n",
      "LevenshteinSimilarity Accuracy: 0.2632\n",
      "MinHashSimilarity Accuracy: 0.4018\n",
      "SimHashSimilarity Accuracy: 0.04114470842332613\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from sklearn.metrics import accuracy_score\n",
    "from model import *\n",
    "\n",
    "# 读取CSV文件\n",
    "texts = []  # 存储句子对和标签\n",
    "with open('data/similarity.csv', 'r', encoding='gbk') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        texts.append((row['sentence1'], row['sentence2'], int(row['label'])))\n",
    "\n",
    "\n",
    "# 函数用于测试模型性能\n",
    "def test_model(model_class, threshold=0.5):\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    for s1, s2, label in texts:\n",
    "        model = model_class(s1, s2)\n",
    "        try:\n",
    "            similarity = model.main()\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        prediction = 1 if similarity >= threshold else 0\n",
    "        predictions.append(prediction)\n",
    "        actuals.append(label - 1)  # 转换label值为0或1\n",
    "\n",
    "    return accuracy_score(actuals, predictions)\n",
    "\n",
    "\n",
    "# 测试每个模型\n",
    "model_classes = [CosineSimilarity, JaccardSimilarity, LevenshteinSimilarity, MinHashSimilarity, SimHashSimilarity]\n",
    "threshold = 0.5  # 可以根据需要调整\n",
    "for model_class in model_classes:\n",
    "    accuracy = test_model(model_class, threshold)\n",
    "    print(f\"{model_class.__name__} Accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T14:44:33.510565500Z",
     "start_time": "2024-03-07T14:43:14.819348400Z"
    }
   },
   "id": "d2ef6e79fa857197"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
